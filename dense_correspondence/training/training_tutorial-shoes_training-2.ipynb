{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting CUDA_VISIBLE_DEVICES =  0,\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch.functional as F\n",
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "from dense_correspondence.training.training import *\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "#utils.set_default_cuda_visible_devices()\n",
    "utils.set_cuda_visible_devices([0]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "from dense_correspondence.training.training import DenseCorrespondenceTraining\n",
    "from dense_correspondence.dataset.spartan_dataset_masked import SpartanDataset\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from dense_correspondence.evaluation.evaluation import DenseCorrespondenceEvaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the configuration for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = utils.getDenseCorrespondenceSourceDir()\n",
    "dataset_config_filename = os.path.join(project_dir, 'data/pdc/trained_models/shoes_consistent_M_background_0.500_3/dataset.yaml')\n",
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SpartanDataset:\n",
      "   - in train mode\n",
      "   - number of scenes 16\n",
      "   - total images:     5849\n"
     ]
    }
   ],
   "source": [
    "dataset = SpartanDataset(config_expanded=dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config_file = os.path.join(project_dir, 'data/pdc/trained_models/shoes_consistent_M_background_0.500_3/training.yaml')\n",
    "\n",
    "train_config = utils.getDictFromYamlFilename(train_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = \"data/pdc/trained_models/my_models\"\n",
    "num_iterations = 3500\n",
    "d = 3 # the descriptor dimension\n",
    "name = \"shoes_training_%d_aploss\" %(d)\n",
    "train_config[\"training\"][\"logging_dir_name\"] = name\n",
    "train_config[\"training\"][\"logging_dir\"] = logging_dir\n",
    "train_config[\"dense_correspondence_network\"][\"descriptor_dimension\"] = d\n",
    "train_config[\"training\"][\"num_iterations\"] = num_iterations\n",
    "\n",
    "TRAIN = True\n",
    "EVALUATE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "\n",
    "This should take about ~12-15 minutes with a GTX 1080 Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training descriptor of dimension 3\n",
      "https://ui.neptune.ai/general-dense-object-nets/general-dense-object-nets/e/SAN-46\n",
      "using SINGLE_OBJECT_WITHIN_SCENE\n",
      "logging_dir: /home/tomasz/code/data/pdc/trained_models/my_models/shoes_training_3_aploss\n",
      "('Saving to params to file: ', '/home/tomasz/code/data/pdc/trained_models/my_models/shoes_training_3_aploss/000000.pth')\n",
      "Epoch 0/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/nn/functional.py:2622: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/tomasz/code/dense_correspondence/network/dense_correspondence_network.py:284: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_tensor = torch.tensor(img_tensor, device=torch.device(\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "('Saving model at iter: ', 500)\n",
      "('Saving to params to file: ', '/home/tomasz/code/data/pdc/trained_models/my_models/shoes_training_3_aploss/999999.pth')\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "\n",
      " empty data, continuing \n",
      "\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "Could not find descriptor image stats...\n",
      "Only normalizing pairs of images!\n",
      "\n",
      " empty data, continuing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All of the saved data for this network will be located in the\n",
    "# code/data/pdc/trained_models/tutorials/caterpillar_3 folder\n",
    "\n",
    "if False:\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "if TRAIN:\n",
    "    print \"training descriptor of dimension %d\" %(d)\n",
    "    train = DenseCorrespondenceTraining(dataset=dataset, config=train_config)\n",
    "    train.run()\n",
    "    print \"finished training descriptor of dimension %d\" %(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "denorm = transforms.Compose([ \n",
    "    transforms.Normalize(mean=[0,0,0], std=[1./0.229, 1./0.224, 1./0.225]), \n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1,1,1])\n",
    "])\n",
    "\n",
    "def denorm_and_plot(tensor_img):\n",
    "    tensor_img = tensor_img.clone().detach().requires_grad_(False)\n",
    "    if tensor_img is None:\n",
    "        return None\n",
    "    denom_img = denorm(tensor_img)\n",
    "    x = denom_img.cpu().detach().numpy()\n",
    "    return x.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dense_correspondence.evaluation.plotting import normalize_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(normalize_descriptor(descriptor[0].detach().cpu().numpy()).transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = data[1]\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.getPaddedString(12345, width=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = data[2].cpu()\n",
    "out = denorm_and_plot(img1[0])\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out * 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate the network quantitatively\n",
    "\n",
    "This should take ~5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = os.path.join(logging_dir, name)\n",
    "model_folder = utils.convert_data_relative_path_to_absolute_path(model_folder)\n",
    "\n",
    "if EVALUATE:\n",
    "    DCE = DenseCorrespondenceEvaluation\n",
    "    num_image_pairs = 100\n",
    "    DCE.run_evaluation_on_network(model_folder, num_image_pairs=num_image_pairs)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `evaluation_quantitative_tutorial.ipynb` for a better place to display the plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
